{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data and make prediction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "# import shap\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "from Translate_and_Create_File import detect_language, translate_list, generate_Resultats_Verticals_Linkedin\n",
    "import warnings\n",
    "from pandas.util import hash_pandas_object\n",
    "from sklearn import preprocessing\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "date_string = time.strftime(\"%Y-%m-%d-%Hh\")\n",
    "\n",
    "\n",
    "def split_dataset(leads_df):\n",
    "    leads_df['Response Creation Date'] = leads_df['Response Creation Date'].map(str)\n",
    "    leads_df['Phone'] = leads_df['Phone'].map(str)\n",
    "\n",
    "    leads_df = leads_df.sort_values(by='Response Creation Date', ascending=True) # Used for the hashing\n",
    "\n",
    "    y = leads_df['Lead Status']\n",
    "    X = leads_df.drop(['Opportunity Name','Opportunity Sales Stage', 'Opportunity Closed As Won/Lost', 'HP Lead ID',\n",
    "                   'Opportunity ClosedWon', 'Opportunity Owner', 'Created Month', 'Last Modified', 'LinkedIn_Glsdr_Industry',\n",
    "                   'Lead Status', 'Status Reason', 'Quantity', 'Lead Qualifier', 'Accept Lead', 'Activ_Disqualified Lead',\n",
    "                   'Opportunity CloseDate', 'Opportunity Created Date', 'Nurture Reason','Willingness to Buy',\n",
    "                   'Nurture Type', 'Lead Source', 'Rating', 'First Name', 'Middle Name', 'Last Name', 'Activ_closed response',\n",
    "                   'Estimated Budget','Primary Campaign','Lead Accepted Date', 'Industry', 'Sub Industry', 'LkdIn_Industry',\n",
    "                   'LkdIn_Company_size','GlsDr_Company size', 'GlsDr_Industry', 'Company_grouped', 'Activ_Re-assigned Lead',\n",
    "                   'Job Role','Activ_Budget Change','Activ_Comments','Activ_Status Change','Job Function', 'Lead Close Reasons'\n",
    "                      ]\n",
    "                      , axis=1)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def hash_data(X):\n",
    "    \n",
    "    leads_obj = X.select_dtypes(include='object')\n",
    "    leads_num = X.select_dtypes(exclude='object')\n",
    "\n",
    "    for i in leads_obj.columns:\n",
    "        leads_obj[i] = leads_obj[i].map(str)\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(leads_obj[i])\n",
    "        leads_obj[i] = le.transform(leads_obj[i])\n",
    "    \n",
    "    X_data = pd.concat([leads_obj,leads_num], axis=1, sort=False)\n",
    "\n",
    "    return X_data\n",
    "\n",
    "\n",
    "def strip_html(htmldoc, strip_tags = ['html','meta','head','body'], outfile=None, verbose=False):\n",
    "    \"\"\"Strip out HTML boilerplate tags but perserve inner content\n",
    "    \n",
    "    Only will strip out the first occurrence of each tag, if multiple occurrences\n",
    "    are desired, function must be modified.\n",
    "    \n",
    "    Args:\n",
    "        htmldoc : str \n",
    "            HTML markup to process\n",
    "        strip_tags : list[str]\n",
    "            list of tags to be stripped out, including any attribute information\n",
    "        outfile : str, optional (default: None)\n",
    "            filename to output stripped html, if None parsed string is returned\n",
    "        verbose : boolean (default: False)\n",
    "            if True, prints removed tags and filepath\n",
    "    \"\"\"\n",
    "    \n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(htmldoc)\n",
    "    \n",
    "    for tag in strip_tags:\n",
    "        rmtag = soup.find(tag)\n",
    "        if rmtag is not None:\n",
    "            rmtag.unwrap()\n",
    "            if verbose: print(tag,'tags removed')\n",
    "    \n",
    "    stripped = soup.prettify()\n",
    "    if outfile is not None:\n",
    "        with open(outfile, 'w', encoding='utf-8') as f:\n",
    "            f.write(stripped)\n",
    "        if verbose: \n",
    "            print(f'file saved to: {outfile}')\n",
    "    else:\n",
    "        return stripped\n",
    "\n",
    "def predict_leads(path, file):\n",
    "    df_new_entries, leads_df = generate_Resultats_Verticals_Linkedin(path, file) #\"data\",\"data12-5-20\"\n",
    "    verticalization_df = pd.read_excel('Verticals Linkedin.xlsx')\n",
    "\n",
    "    leads_df = leads_df.sort_values(by='Week', ascending=False)\n",
    "    leads_df.drop_duplicates(subset =\"ResponseId\", keep=\"last\", inplace = True) \n",
    "    leads_df = leads_df[leads_df.columns.drop(list(leads_df.filter(regex='Unnamed:')))] # drops all cols with unnamed\n",
    "\n",
    "    leads_df = leads_df.merge(verticalization_df, left_on='LkdIn_Industry', right_on='LinkedIn_Industry', how='left')\n",
    "\n",
    "    ### SALESFORCE STATUS\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('Contacting', 'Work In Progress')\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('Interest', 'Work In Progress')\n",
    "\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('Converted', 'Qualified')\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('Qualification', 'Qualified')\n",
    "\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('Closed', 'Disqualified')\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('New', 'Unqualified')\n",
    "\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('Sales Nurture', 'Nurture')\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('Sales Qualified', 'Nurture')\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('List', 'Nurture')\n",
    "    leads_df[\"Lead Status\"] = leads_df[\"Lead Status\"].replace('Market Development', 'Nurture')\n",
    "\n",
    "    ### GROUPBY COMPANIES\n",
    "    leads_df['Company'] = leads_df['Company'].str.lower()\n",
    "    company_count = leads_df.groupby(['Company']).size().to_frame('count').reset_index()\n",
    "    company_count = company_count.rename(columns={\"Company\": \"Company_grouped\", \"count\": \"Count_account\"})\n",
    "    leads_df = leads_df.merge(company_count, left_on='Company', right_on='Company_grouped', how='left')\n",
    "    leads_df[\"Count_account\"] = pd.to_numeric(leads_df[\"Count_account\"])\n",
    "\n",
    "\n",
    "    ### PHONE OR LANDLINE\n",
    "    leads_df[\"Phone\"] = leads_df[\"Phone\"].str.replace(' ', '')\n",
    "    leads_df[\"Phone\"] = leads_df[\"Phone\"].str.replace('-', '')\n",
    "    leads_df[\"Phone\"] = leads_df[\"Phone\"].str.replace('–', '')\n",
    "    leads_df[\"Phone\"] = leads_df[\"Phone\"].str.replace('/', '')\n",
    "    leads_df[\"Phone\"] = leads_df[\"Phone\"].str.replace('.', '')\n",
    "    leads_df[\"Phone\"] = leads_df[\"Phone\"].str.replace('(', '')\n",
    "    leads_df[\"Phone\"] = leads_df[\"Phone\"].str.replace(')', '')\n",
    "    leads_df[\"Phone\"] = leads_df[\"Phone\"].str.replace('+', '')\n",
    "    leads_df[\"Phone\"] = leads_df[\"Phone\"].str.replace('^00', '')\n",
    "\n",
    "\n",
    "    leads_df[\"Phone\"].head(100)\n",
    "    leads_df['Phone_desc'] = np.where(((leads_df[\"Phone\"].str.startswith('4915')) | \n",
    "                                          (leads_df[\"Phone\"].str.startswith('4916')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('4917')) &\n",
    "                                          (leads_df[\"Subregion\"]==\"Germany\")),\"Phone\",\n",
    "\n",
    "                                           np.where((((leads_df[\"Phone\"].str.startswith('447')) | \n",
    "                                          (leads_df[\"Phone\"].str.startswith('3538'))) &\n",
    "                                          (leads_df[\"Subregion\"]==\"UK&I\")),\"Phone\",\n",
    "\n",
    "                                           np.where((((leads_df[\"Phone\"].str.startswith('346')) | \n",
    "                                          (leads_df[\"Phone\"].str.startswith('6')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('3519'))) &\n",
    "                                          (leads_df[\"Subregion\"]==\"IBERIA\")),\"Phone\",\n",
    "\n",
    "                                           np.where((((leads_df[\"Phone\"].str.startswith('337')) | \n",
    "                                          (leads_df[\"Phone\"].str.startswith('336'))) &\n",
    "                                          (leads_df[\"Subregion\"]==\"France\")),\"Phone\",\n",
    "\n",
    "                                           np.where((((leads_df[\"Phone\"].str.startswith('393')) | \n",
    "                                          (leads_df[\"Phone\"].str.startswith('3567')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('3569'))) &\n",
    "                                          (leads_df[\"Subregion\"]==\"Italy & Malta\")),\"Phone\",\n",
    "\n",
    "                                           np.where((((leads_df[\"Phone\"].str.startswith('467')) | \n",
    "                                          (leads_df[\"Phone\"].str.startswith('474')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('475')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('479')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('453')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('454')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('455')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('456')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('457')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('458'))) &\n",
    "                                          (leads_df[\"Subregion\"]==\"NORDICS\")),\"Phone\",\n",
    "\n",
    "                                           np.where((((leads_df[\"Phone\"].str.startswith('436')) | \n",
    "                                          (leads_df[\"Phone\"].str.startswith('417'))) &\n",
    "                                          (leads_df[\"Subregion\"]==\"ACH\")),\"Phone\",\n",
    "\n",
    "                                           np.where((((leads_df[\"Phone\"].str.startswith('324')) | \n",
    "                                          (leads_df[\"Phone\"].str.startswith('316'))) &\n",
    "                                          (leads_df[\"Subregion\"]==\"BENELUX\")),\"Phone\",\n",
    "\n",
    "                                           np.where((((leads_df[\"Phone\"].str.startswith('485')) | \n",
    "                                          (leads_df[\"Phone\"].str.startswith('484')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('486')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('487')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('488')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('9725')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('362')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('363')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('365')) |\n",
    "                                          (leads_df[\"Phone\"].str.startswith('366'))) &\n",
    "                                          (leads_df[\"Subregion\"]==\"CEE+IL\")),\"Phone\",\n",
    "\n",
    "                                           np.where(leads_df['Phone'].isnull(),\"No Phone\",\n",
    "                                           \"Landline\"))))))))))\n",
    "\n",
    "\n",
    "    ### 3D COMPANY?\n",
    "    leads_df[\"3D_Company?\"] = leads_df[\"Company\"].astype(str) + leads_df[\"LkdIn_Translation\"].str.lower().astype(str)\n",
    "    leads_df[\"3D_Company?\"] = leads_df[\"3D_Company?\"].str.contains('3d', na=False, regex=True)*1\n",
    "\n",
    "\n",
    "    ### CLEAN HP VERTICALS\n",
    "    leads_df['Coments Verticals']=np.where(leads_df['Coments Verticals'].str.startswith('Proveedores de piezas 3D'),\n",
    "                                      \"3D_Parts_Provider\",leads_df['Coments Verticals'])\n",
    "\n",
    "    leads_df['Coments Verticals']=np.where(leads_df['Coments Verticals'].str.startswith('Movilidad y'),\n",
    "                                      \"3D_Mobility_and_Transportation\",leads_df['Coments Verticals'])\n",
    "\n",
    "    leads_df['Coments Verticals']=np.where(leads_df['Coments Verticals'].str.startswith('Tubos y Sistemas'),\n",
    "                                      \"3D_Industrial\",leads_df['Coments Verticals'])\n",
    "\n",
    "    leads_df['Coments Verticals']=np.where(leads_df['Coments Verticals'].str.startswith('Tecnología y'),\n",
    "                                      \"3D_Education_and_Research\",leads_df['Coments Verticals'])\n",
    "\n",
    "    leads_df['Coments Verticals']=np.where(leads_df['Coments Verticals'].str.startswith('Maquinaria y equipamiento'),\n",
    "                                      \"3D_Industrial\",leads_df['Coments Verticals'])\n",
    "\n",
    "    leads_df['Coments Verticals']=np.where(leads_df['Coments Verticals'].str.startswith('Mecanizadores'),\n",
    "                                      \"3D_Industrial\",leads_df['Coments Verticals'])\n",
    "\n",
    "    leads_df['Coments Verticals']=np.where(leads_df['Coments Verticals'].str.startswith('Moldistas'),\n",
    "                                      \"3D_Industrial\",leads_df['Coments Verticals'])\n",
    "\n",
    "    leads_df['Coments Verticals']=np.where(leads_df['Coments Verticals'].str.startswith('Prótesis y Ortesis'),\n",
    "                                      \"3D_Healthcare\",leads_df['Coments Verticals'])\n",
    "\n",
    "    leads_df['Coments Verticals']=np.where(leads_df['Coments Verticals'].str.startswith('3D_OUT_OF_SCOPE'),\n",
    "                                      \"3D_Out_of_Scope\",leads_df['Coments Verticals'])\n",
    "\n",
    "    leads_df[\"Coments Verticals\"] = leads_df[\"Coments Verticals\"].replace('undefined', np.nan)\n",
    "    leads_df[\"Coments Verticals\"] = leads_df[\"Coments Verticals\"].replace('Mobility and Transportation', '3D_Mobility_and_Transportation')\n",
    "    leads_df[\"Coments Verticals\"] = leads_df[\"Coments Verticals\"].replace('Education and Research', '3D_Education_and_Research')\n",
    "    leads_df[\"Coments Verticals\"] = leads_df[\"Coments Verticals\"].replace('Consumer Goods and Electronics', '3D_Consumer_Goods_and_Electronics')\n",
    "    leads_df[\"Coments Verticals\"] = leads_df[\"Coments Verticals\"].replace('Healthcare', '3D_Healthcare')\n",
    "    leads_df[\"Coments Verticals\"] = leads_df[\"Coments Verticals\"].replace('Military and Defense and Aerospace', '3D_Military_and_Defense_and_Aerospace')\n",
    "    leads_df[\"Coments Verticals\"] = leads_df[\"Coments Verticals\"].replace('Militar', '3D_Military_and_Defense_and_Aerospace')\n",
    "    leads_df[\"Coments Verticals\"] = leads_df[\"Coments Verticals\"].replace('Militar, defensa y aeroespacialDepartamento de defensa', '3D_Military_and_Defense_and_Aerospace')\n",
    "\n",
    "    leads_df['Coments Verticals'].unique()\n",
    "\n",
    "\n",
    "    ### JOIN already known verticals with LinkedIn\n",
    "\n",
    "    leads_df['HP_and_LnkdIn_Verticals'] = leads_df['Coments Verticals'].fillna(leads_df['LinkedIn_HP_Verticals'])\n",
    "    leads_df['LnkdIn_and_Glsdr_Employees'] = leads_df['LkdIn_Company_size'].fillna(leads_df['GlsDr_Company size'])\n",
    "\n",
    "    ### LEAD NUMBER\n",
    "    leads_df['HP Lead ID'] = leads_df['HP Lead ID'].str.replace('LEAD-', '')\n",
    "    leads_df[\"HP Lead ID\"] = pd.to_numeric(leads_df[\"HP Lead ID\"])\n",
    "    leads_df['ResponseId'] = leads_df['ResponseId'].str.replace('3DMCR-R', '')\n",
    "    leads_df[\"ResponseId\"] = pd.to_numeric(leads_df[\"ResponseId\"])\n",
    "\n",
    "\n",
    "    ### Have phone or Email?\n",
    "    leads_df[\"Phone_or_Email\"] = leads_df[\"Phone\"]\n",
    "    leads_df['Phone_or_Email'] = leads_df['Phone_or_Email'].fillna(leads_df['Email'])\n",
    "    leads_df['Phone_or_Email'] = np.where(leads_df['Phone_or_Email'].isnull(), 0, 1)\n",
    "\n",
    "\n",
    "    ### Have LinkedIn or Glassdoor?\n",
    "    leads_df[\"Lnkdin_or_Glsdr\"] = leads_df[\"LkdIn_Web_Name\"]\n",
    "    leads_df['Lnkdin_or_Glsdr'] = leads_df['Lnkdin_or_Glsdr'].fillna(leads_df['GlsDr_Company size'])\n",
    "    leads_df['Lnkdin_or_Glsdr'] = np.where(leads_df['Lnkdin_or_Glsdr'].isnull(), 0, 1)\n",
    "\n",
    "\n",
    "    ### Income clearning\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('Desconocido/No aplicable por año', '0')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('Desconocido/No aplicable', '0')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 10 a 25\\xa0millones\\xa0(EUR) por año', '25000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 1000 a 2000\\xa0millones\\xa0(EUR) por año', '2000000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 500 a 1000\\xa0millones\\xa0(EUR) por año', '1000000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 5000 a 10\\xa0000\\xa0millones\\xa0(EUR) por año', '10000000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 50 a 100\\xa0millones\\xa0(EUR) por año', '25000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 100 a 500\\xa0millones\\xa0(EUR) por año', '500000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 1 a 5\\xa0millones\\xa0(EUR) por año', '5000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 25 a 50\\xa0millones\\xa0(EUR) por año', '50000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('Menos de 1\\xa0millón\\xa0(EUR) por año', '1000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 2000 a 5000\\xa0millones\\xa0(EUR) por año', '5000000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('Más de 10\\xa0000\\xa0millones\\xa0(EUR) por año', '100000000000')\n",
    "    leads_df[\"GlsDr_Income\"] = leads_df[\"GlsDr_Income\"].replace('De 5 a 10\\xa0millones\\xa0(EUR) por año', '100000000')\n",
    "    leads_df[\"GlsDr_Income\"].fillna(0, inplace=True)\n",
    "    leads_df[\"GlsDr_Income\"] = pd.to_numeric(leads_df[\"GlsDr_Income\"])\n",
    "\n",
    "\n",
    "    ### Company size\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].str.replace('�',' ')\n",
    "\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('10,001+ employees', '15000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('5,001-10,000 employees', '10000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('1,001-5,000 employees', '5000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('501-1,000 employees', '1000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('201-500 employees', '500')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('51-200 employees', '200')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('11-50 employees', '50')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('2-10 employees', '10')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('0-1 employees', '1')\n",
    "\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('Más de 10\\xa0000\\xa0empleados', '15000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('M s de 10 000 empleados', '15000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 5001 a 10\\xa0000\\xa0empleados', '10000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 5001 a 10 000 empleados', '10000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 1001 a 5000\\xa0empleados', '5000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 1001 a 5000\\xa0empleados', '5000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 1001 a 5000 empleados', '5000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 501 a 1000\\xa0empleados', '1000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 501 a 1000 empleados', '1000')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 201 a 500 empleados', '500')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 201 a 500\\xa0empleados', '500')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 51 a 200 empleados', '200')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 51 a 200 empleados', '200')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 51 a 200\\xa0empleados', '200')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 1 a 50\\xa0empleados', '50')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('De 1 a 50 empleados', '50')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = leads_df[\"LnkdIn_and_Glsdr_Employees\"].replace('Desconocido', '0')\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"].fillna(0, inplace=True)\n",
    "    leads_df[\"LnkdIn_and_Glsdr_Employees\"] = pd.to_numeric(leads_df[\"LnkdIn_and_Glsdr_Employees\"])\n",
    "\n",
    "\n",
    "    ### Words and their appearences\n",
    "    leads_df['LkdIn_Translation'] = leads_df['LkdIn_Translation'].str.lower()\n",
    "    leads_df['LkdIn_Translation'] = leads_df['LkdIn_Translation'].str.replace('-', '')\n",
    "    leads_df['LkdIn_Translation'] = leads_df['LkdIn_Translation'].str.replace('/', ',')\n",
    "    leads_df['LkdIn_Translation'] = leads_df['LkdIn_Translation'].str.replace(' and ', ',')\n",
    "    leads_df[\"LkdIn_Translation\"] = leads_df[\"LkdIn_Translation\"].str.split(\",\", n = 5, expand = True) \n",
    "\n",
    "    from collections import Counter \n",
    "    import re\n",
    "\n",
    "    corpus = leads_df[\"LkdIn_Translation\"].dropna().tolist()\n",
    "    corpus = [item.strip() for item in corpus]\n",
    "\n",
    "    def highest_occurrence_words(corpus):  \n",
    "        Counters = Counter(corpus) \n",
    "        most_occur = Counters.most_common()\n",
    "        return(most_occur)\n",
    "\n",
    "    most_occur = highest_occurrence_words(corpus)\n",
    "\n",
    "    for word in most_occur[:50]:\n",
    "        leads_df.loc[leads_df['LkdIn_Translation'].str.contains(word[0], na=False), 'LkdIn_Translation'] = word[0]\n",
    "\n",
    "    ### Fiscal Years\n",
    "    leads_df['Month'] = leads_df['Response Creation Date'].dt.month\n",
    "    leads_df['Year'] = leads_df['Response Creation Date'].dt.year\n",
    "\n",
    "    leads_df[\"Quarter\"] = np.where(leads_df[\"Month\"]==1,1,\"\")\n",
    "    leads_df[\"Quarter\"] = np.where(np.logical_and(leads_df[\"Month\"]>=2, leads_df[\"Month\"]<=4), 2,\n",
    "                                  np.where(np.logical_and(leads_df[\"Month\"]>=5, leads_df[\"Month\"]<=7), 3,\n",
    "                                    np.where(np.logical_and(leads_df[\"Month\"]>=8, leads_df[\"Month\"]<=10), 4, 1)\n",
    "                                          ))\n",
    "    leads_df[\"Fiscal_Year\"] = np.where(np.logical_and(leads_df[\"Month\"]>=1, leads_df[\"Month\"]<=10), \n",
    "                                       leads_df['Year'], leads_df['Year']+1)\n",
    "\n",
    "    leads_df['FY Correct'] = pd.to_numeric(leads_df[\"Fiscal_Year\"].map(str)+leads_df[\"Quarter\"].map(str))\n",
    "\n",
    "\n",
    "    ### Timeframe to Buy\n",
    "    leads_df[\"Timeframe to Buy\"].unique()\n",
    "    leads_df[\"Timeframe to Buy\"] = leads_df[\"Timeframe to Buy\"].replace('< 1 Week', '0.25')\n",
    "    leads_df[\"Timeframe to Buy\"] = leads_df[\"Timeframe to Buy\"].replace('< 1 Month', '1')\n",
    "    leads_df[\"Timeframe to Buy\"] = leads_df[\"Timeframe to Buy\"].replace('3 - 6 Months', '6')\n",
    "    leads_df[\"Timeframe to Buy\"] = leads_df[\"Timeframe to Buy\"].replace('6 - 12 Months', '12')\n",
    "    leads_df[\"Timeframe to Buy\"] = leads_df[\"Timeframe to Buy\"].replace('1 - 3 Months', '3')\n",
    "    leads_df[\"Timeframe to Buy\"] = leads_df[\"Timeframe to Buy\"].replace('> 1 Year', '18')\n",
    "\n",
    "    leads_df[\"Timeframe to Buy\"].fillna(0, inplace=True)\n",
    "    leads_df[\"Timeframe to Buy\"] = pd.to_numeric(leads_df[\"Timeframe to Buy\"])\n",
    "\n",
    "\n",
    "    ### Split dataset\n",
    "    leads_df_train = leads_df\n",
    "\n",
    "    leads_df_train = leads_df_train[leads_df_train[\"Lead Status\"]!='Unqualified']\n",
    "    leads_df_train = leads_df_train[leads_df_train[\"Lead Status\"]!='Work In Progress']\n",
    "\n",
    "    X, y = split_dataset(leads_df_train)\n",
    "\n",
    "    X_data = hash_data(X)\n",
    "\n",
    "\n",
    "    ### New Data\n",
    "    new_companies = df_new_entries[\"Name\"]\n",
    "    new_companies_lower = [x.lower() for x in new_companies]\n",
    "    new_comp_leads = leads_df.loc[leads_df['Company'].isin(new_companies_lower)]\n",
    "\n",
    "    wanted_status = [\"Unqualified\",\"Work In Progress\"]\n",
    "    open_new_leads = new_comp_leads.loc[new_comp_leads['Lead Status'].isin(wanted_status)]\n",
    "\n",
    "\n",
    "    X_new, y_new = split_dataset(open_new_leads)\n",
    "    X_data_new = hash_data(X_new)\n",
    "    X_data_new.fillna((0), inplace=True) \n",
    "\n",
    "\n",
    "\n",
    "    ### Loading Model\n",
    "\n",
    "    import pickle\n",
    "    xgb_model_loaded = pickle.load(open(\"xgb_grid_val_27_06\", \"rb\"))\n",
    "\n",
    "    X_new_matrix = X_data_new.values\n",
    "    pred_results = xgb_model_loaded.predict(X_new_matrix)\n",
    "    pred_proba_results = xgb_model_loaded.predict_proba(X_new_matrix)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    ### Explain every entry\n",
    "    from IPython.display import Image, display_html\n",
    "    from lime.lime_tabular import LimeTabularExplainer\n",
    "    lead_nb = 0\n",
    "    limeparams = dict(\n",
    "        training_data = X_data.values, \n",
    "        training_labels = y.values,\n",
    "        feature_names = list(X_data.columns), \n",
    "        class_names = ['Disqualified','Good'],\n",
    "        discretize_continuous=False\n",
    "    )\n",
    "    lte = LimeTabularExplainer(**limeparams)\n",
    "    print('Predicted:', pred_results[lead_nb], round(pred_proba_results[lead_nb],5))\n",
    "\n",
    "    lte_expl = lte.explain_instance(X_data_new.iloc[lead_nb], xgb_model_loaded.predict_proba, num_features=15)\n",
    "    display_html(strip_html(lte_expl.as_html()), raw=True)\n",
    "    lte_expl.as_list()\n",
    "\n",
    "    from IPython.display import Image, display_html\n",
    "    from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "    explanation = []\n",
    "    for i in range(0,len(X_data_new)):\n",
    "        lte_expl = lte.explain_instance(X_data_new.iloc[i], xgb_model_loaded.predict_proba, num_features=5)\n",
    "        explanation.append(lte_expl.as_list())\n",
    "        print(f'{i+1}/{len(X_data_new)}\\r', end=\"\")\n",
    "\n",
    "    result_val = pd.DataFrame(np.vstack((X_data_new[\"ResponseId\"][:len(explanation)], \n",
    "                                         pred_proba_results[:len(explanation)])).T, \n",
    "                                         columns=[\"ResponseId\",\"Pred Prob\"])  #1 is good\n",
    "    result_val['Explainability'] = pd.Series(explanation, index=result_val.index)\n",
    "    result_val['ResponseId'] = result_val['ResponseId'].astype(int)\n",
    "\n",
    "    result_val[['Exaplain_1', 'Exaplain_2', 'Exaplain_3', 'Exaplain_4', 'Exaplain_5']] = pd.DataFrame(result_val['Explainability'].tolist(), \n",
    "                                                                                                       index=result_val.index)  \n",
    "    result_val = result_val.drop([\"Explainability\"], axis=1)\n",
    "    result_val['ResponseId'] = '3DMCR-R' + result_val['ResponseId'].astype(str)\n",
    "\n",
    "    print(\"Saving the results\")\n",
    "    result_val.to_excel(f'Prediction Leads{date_string}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'All_data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c0e0e273a717>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_leads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"NewData\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-6145ecd45043>\u001b[0m in \u001b[0;36mpredict_leads\u001b[1;34m(path, file)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_leads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0mdf_new_entries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleads_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_Resultats_Verticals_Linkedin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#\"data\",\"data12-5-20\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[0mverticalization_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Verticals Linkedin.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - HP Inc\\Reports\\Salesforce ML\\Machine Learning\\main\\Translate_and_Create_File.py\u001b[0m in \u001b[0;36mgenerate_Resultats_Verticals_Linkedin\u001b[1;34m(path, file)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_Resultats_Verticals_Linkedin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mmerge_new_entires\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Example: (\"data\",\"data26-4-20\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0mscrape_glassdoor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mscrape_linkedin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - HP Inc\\Reports\\Salesforce ML\\Machine Learning\\main\\Detect_New_Entries.py\u001b[0m in \u001b[0;36mmerge_new_entires\u001b[1;34m(path, filename)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mdate_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y-%m-%d-%Hh\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mall_leads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'All_data.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;31m#     new_leads = pd.read_csv('Scraping/data/all_time_goods.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mincome_leads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{path}/{filename}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m             raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'All_data.xlsx'"
     ]
    }
   ],
   "source": [
    "predict_leads(\"data\",\"NewData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
