{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Leads in Glassdoor Scraping Revenue: 196\n"
     ]
    }
   ],
   "source": [
    "path = \"data\"\n",
    "filename = \"NewData\"\n",
    "\n",
    "import os, random, sys, time\n",
    "# from urllib.parse import urlparse\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from Detect_New_Entries import detect_new_entires, merge_new_entires\n",
    "import time\n",
    "\n",
    "# Scrapes the new data from glassdoor\n",
    "# and saves it to the Scrapping revenue.xlsx\n",
    "from selenium import webdriver\n",
    "#     browser = webdriver.Chrome(executable_path=r'C:\\path\\to\\chromedriver.exe')\n",
    "#     browser.get('http://google.com/')\n",
    "\n",
    "### LEADS MISSING\n",
    "##############################################################\n",
    "leads_df = pd.read_excel('Glassdoor_Scraping_Revenue.xlsx') #Glassdoor_Scraping_Revenue.xlsx\n",
    "original_leads = pd.read_excel(f'{path}/{filename}.xlsx')\n",
    "\n",
    "### LEADS MISSING - NOT CASE SENSITIVE\n",
    "##############################################################\n",
    "original_leads = original_leads.rename({'Company / Account':'Company'}, axis=1)\n",
    "scraped_comp = pd.DataFrame(leads_df['Name'].str.lower().unique(),columns=[\"Comp\"]).dropna()\n",
    "orig_leads = pd.DataFrame(original_leads['Company'].str.lower().unique(),columns=[\"Comp\"]).dropna()\n",
    "\n",
    "to_scrape = orig_leads.merge(scraped_comp,indicator = True, how='left').loc[lambda x : x['_merge']!='both']\n",
    "new_leads = to_scrape['Comp']\n",
    "#     new_leads = list(set(scraped_comp) - set(orig_leads))\n",
    "print(\"New Leads in Glassdoor Scraping Revenue:\", len(new_leads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOGIN\n",
    "##############################################################\n",
    "browser = webdriver.Chrome('driver/chromedriver83.exe')\n",
    "browser.get('https://www.glassdoor.es/profile/login_input.htm?userOriginHook=HEADER_SIGNIN_LINK')\n",
    "\n",
    "file = open('CONFIG/config_glassdoor.txt')\n",
    "lines = file.readlines()\n",
    "username = lines[0]\n",
    "password = lines[1]\n",
    "\n",
    "time.sleep(round(random.uniform(1, 2),2))\n",
    "\n",
    "##############################################################\n",
    "elementID = browser.find_element_by_id('userEmail')\n",
    "elementID.send_keys(username)\n",
    "time.sleep(round(random.uniform(1, 1.3),2))\n",
    "\n",
    "elementID = browser.find_element_by_id('userPassword')\n",
    "elementID.send_keys(password)\n",
    "time.sleep(round(random.uniform(1, 2),2))\n",
    "\n",
    "elementID.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New companies: 196\n"
     ]
    }
   ],
   "source": [
    "# READ\n",
    "##############################################################\n",
    "company_list = new_leads\n",
    "company_list = company_list.dropna() \n",
    "company_list = company_list.drop_duplicates()\n",
    "company_list = company_list.tolist()\n",
    "companies = company_list\n",
    "print(\"New companies:\", len(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Scraping: 0.51% completed - eurl cyril orthopedie\n",
      "2: Scraping: 1.02% completed - hd soft\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=84.0.4147.89)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1fba0fb52d7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \"\"\"\n\u001b[1;32m--> 679\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=84.0.4147.89)\n"
     ]
    }
   ],
   "source": [
    "### LOOP\n",
    "##############################################################\n",
    "companies_list = []\n",
    "companies_count = 0\n",
    "\n",
    "browser.get('https://www.glassdoor.es/Opiniones/barcelona-hp-opiniones-SRCH_IL.0,9_IM1015_KE10,12.htm')\n",
    "\n",
    "for company in companies:\n",
    "    error = False\n",
    "    inside_page = False\n",
    "    headers_list = []\n",
    "    comp_data_list = []\n",
    "\n",
    "    headers_list.append('Name')\n",
    "    comp_data_list.append(company)\n",
    "    browser.get('https://www.glassdoor.es/Opiniones/barcelona-hp-opiniones-SRCH_IL.0,9_IM1015_KE10,12.htm')\n",
    "\n",
    "    time.sleep(round(random.uniform(3, 4),2))\n",
    "\n",
    "    try: \n",
    "        elementID = browser.find_element_by_id('sc.keyword')\n",
    "    except: ## ERROR WHEN IT GETS OUT OF THE OPINIONS SEARCH\n",
    "        browser.get('https://www.glassdoor.es/Opiniones/barcelona-hp-opiniones-SRCH_IL.0,9_IM1015_KE10,12.htm')\n",
    "        error = True\n",
    "    elementID = browser.find_element_by_id('sc.keyword')\n",
    "    elementID.send_keys(Keys.CONTROL, 'a')\n",
    "    elementID.send_keys(Keys.BACKSPACE)\n",
    "    elementID.send_keys(company)\n",
    "    elementID.submit()\n",
    "\n",
    "\n",
    "    time.sleep(round(random.uniform(5, 7),2))\n",
    "\n",
    "    ### SOMETIMES IT ENTERS THE PAGE DIRECTLY\n",
    "    try:\n",
    "#         browser.find_element_by_xpath(\"//span[@class='sqLogo tighten lgSqLogo logoOverlay']//img\").click()\n",
    "        browser.find_element_by_xpath(\"//div[contains(@class,'companySearchHierarchies gdGrid')]//div[1]//div[1]//div[1]//div[1]//div[2]//h2[1]//a[1]\").click()\n",
    "        inside_page = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # IF COMPANY NOT FOUND, CATCH.\n",
    "    if inside_page == False:\n",
    "        try:\n",
    "            browser.find_element_by_xpath(\"//body[contains(@class,'_initOk noTouch tablet mobileFF')]/div[contains(@class,'pageContentWrapper')]/div[@id='PageContent']/div[@id='PageBodyContents']/div[contains(@class,'pageInsideContent cf')]/div[@id='EI-Srch']/div[@id='SearchResults']/div[@id='ReviewSearchResults']/article[@id='MainCol']/div[contains(@class,'module')]/div[2]/div[1]/div[2]/div[1]\").click()  \n",
    "        except NoSuchElementException:  #spelling error making this code not work as expected\n",
    "            error = True\n",
    "\n",
    "    time.sleep(round(random.uniform(5, 6),2))    \n",
    "\n",
    "    if error==False:    \n",
    "        src = browser.page_source\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "        try:\n",
    "            company_div = soup.find('div', {'class': 'info flexbox row col-hh'})\n",
    "            header = company_div.find_all('label')\n",
    "            info = company_div.find_all('span')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for i in range(0,len(header)):\n",
    "            headers_list.append(header[i].get_text().strip())\n",
    "            comp_data_list.append(info[i].get_text().strip())\n",
    "\n",
    "    companies_list.append(headers_list)\n",
    "    companies_list.append(comp_data_list)\n",
    "\n",
    "    companies_count = companies_count+1\n",
    "    if companies_count % 250 == 0:\n",
    "        time.sleep(round(random.uniform(65, 90),2))\n",
    "    print('{}: Scraping: {}% completed - {}'.format(companies_count,round(companies_count/len(companies)*100,2),company))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_list\n",
    "\n",
    "grid_header = ['Name','Sitio web', 'Sede', 'Tamaño', 'Fundada en', 'Tipo', 'Sector', 'Ingresos']\n",
    "dataframe = []\n",
    "\n",
    "for k in range(0,companies_count):\n",
    "    j = 0\n",
    "    i = 0\n",
    "    lista = []\n",
    "\n",
    "    while i< len(grid_header):\n",
    "        try:\n",
    "            if grid_header[i] == companies_list[0+k*2][j]:\n",
    "                field = companies_list[1+k*2][j]\n",
    "            else:\n",
    "                field = None\n",
    "                j -= 1\n",
    "            lista.append(field)\n",
    "            j +=1\n",
    "\n",
    "        except:\n",
    "            lista.append(None)\n",
    "        i += 1    \n",
    "    dataframe.append(lista)\n",
    "\n",
    "df = pd.DataFrame.from_records(dataframe,columns=grid_header)\n",
    "df = df[df[\"Sitio web\"] != 'global.mandg.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sitio web</th>\n",
       "      <th>Sede</th>\n",
       "      <th>Tamaño</th>\n",
       "      <th>Fundada en</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Ingresos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>maflow</td>\n",
       "      <td>www.maflow.com</td>\n",
       "      <td>Pune (India)</td>\n",
       "      <td>De 1001 a 5000 empleados</td>\n",
       "      <td>Desconocido(a)</td>\n",
       "      <td>Empresa privada</td>\n",
       "      <td>Desconocido(a)</td>\n",
       "      <td>Desconocido/No aplicable por año</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name       Sitio web          Sede                    Tamaño  \\\n",
       "0  maflow  www.maflow.com  Pune (India)  De 1001 a 5000 empleados   \n",
       "\n",
       "       Fundada en             Tipo          Sector  \\\n",
       "0  Desconocido(a)  Empresa privada  Desconocido(a)   \n",
       "\n",
       "                           Ingresos  \n",
       "0  Desconocido/No aplicable por año  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glassdoor Scraping Revenue and its backups saved correctly.\n"
     ]
    }
   ],
   "source": [
    "### SAVE\n",
    "##############################################################\n",
    "prev_file = pd.read_excel(\"Glassdoor_Scraping_Revenue.xlsx\")\n",
    "date_string = time.strftime(\"%Y-%m-%d-%Hh\")\n",
    "\n",
    "out_grid_header = ['Name','Sitio web', 'Sede', 'Tamaño', 'Fundada en', 'Tipo', 'Sector', \n",
    "                   'Ingresos','Translated?','Translation_sector']\n",
    "\n",
    "mix_file = prev_file.append(df)\n",
    "mix_file = mix_file.drop(columns=['Unnamed: 0'])\n",
    "mix_file = mix_file[out_grid_header]\n",
    "\n",
    "mix_file.to_excel(\"Glassdoor_Scraping_Revenue.xlsx\")\n",
    "mix_file.to_excel(f'backups_scrape/Glassdoor_Scraping_Revenue{date_string}.xlsx')\n",
    "print(\"Glassdoor Scraping Revenue and its backups saved correctly.\")\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
